spring:
    application:
        name: spring_with_ai

    ai:
        ollama:
            base-url: http://localhost:11434
            chat:
                options:
                    model: mistral
                    temperature: 0.7

# This project will work if you have installed and have running mistral model